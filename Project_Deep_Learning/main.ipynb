{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining CNN Model\n",
    "\n",
    "from keras.models import Sequential    #For initialising the model\n",
    "from keras.layers import Conv2D        #For adding convolutional layer\n",
    "from keras.layers import MaxPooling2D  #For adding max pooling layer\n",
    "from keras.layers import Flatten       #For flattening max pooled layer values into a single vector\n",
    "from keras.layers import Dense         #For adding layers to NN\n",
    "\n",
    "h_layers = 1   #no. of hidden layers\n",
    "features = 32  #no. of feature maps \n",
    "neurons = 128  #no. of neurons in each hidden layer\n",
    "\n",
    "model = Sequential() #initialise the model\n",
    "\n",
    "model.add( Conv2D( features, (3, 3),input_shape = (64, 64, 1), activation = 'relu' )) #Dims of feature map = 3*3, accepting 64*64 pixels grayscale images\n",
    "model.add( MaxPooling2D( pool_size = (2, 2) )) #add max pooling layer, with dims of each pool = 2*2\n",
    "\n",
    "model.add( Flatten() ) #add flattening layer \n",
    "    \n",
    "for i in range( h_layers ):  #add all hidden layers\n",
    "    model.add( Dense( units = neurons, activation = 'relu' ))\n",
    "        \n",
    "model.add( Dense( units = 1, activation = 'sigmoid' ))  #add an output layer\n",
    "\n",
    "model.compile( optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'] )  #define optimizer and loss functions as well as required metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all images into grayscale JPEG format\n",
    "\n",
    "from PIL import Image  #For manipulating images\n",
    "import glob            #For accessing all image files \n",
    "\n",
    "#Converting all images in training as well as testing sets to grayscale JPEG format\n",
    "for fil in glob.glob(r'dataset\\train_set\\yes\\*.*'):\n",
    "    img = Image.open(fil)\n",
    "    img = img.convert('L') \n",
    "    img.save(fil, format = 'JPEG')\n",
    "\n",
    "for fil in glob.glob(r'dataset\\train_set\\no\\*.*'):\n",
    "    img = Image.open(fil)\n",
    "    img = img.convert('L') \n",
    "    img.save(fil, format = 'JPEG')\n",
    "\n",
    "for fil in glob.glob(r'dataset\\test_set\\yes\\*.*'):\n",
    "    img = Image.open(fil)\n",
    "    img = img.convert('L') \n",
    "    img.save(fil, format = 'JPEG')\n",
    "\n",
    "for fil in glob.glob(r'dataset\\test_set\\no\\*.*'):\n",
    "    img = Image.open(fil)\n",
    "    img = img.convert('L') \n",
    "    img.save(fil, format = 'JPEG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation and converting images so that they can be fed into the CNN\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)  #Rescaling all pixel values from 0-255 range to 0-1 range\n",
    "\n",
    "train = datagen.flow_from_directory('dataset/train_set',        #creating training data               \n",
    "                                     target_size=(64, 64),\n",
    "                                     batch_size=32,\n",
    "                                     color_mode='grayscale',\n",
    "                                     class_mode='binary')\n",
    "\n",
    "test = datagen.flow_from_directory('dataset/test_set',          #creating testing data\n",
    "                                    target_size=(64, 64),\n",
    "                                    batch_size=32,\n",
    "                                    color_mode='grayscale',\n",
    "                                    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model to training and testing data and saving the model\n",
    "\n",
    "history = model.fit_generator(train,\n",
    "                    steps_per_epoch=181,\n",
    "                    epochs=50,\n",
    "                    validation_data=test,\n",
    "                    validation_steps=78)\n",
    "\n",
    "import h5py\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Training and Testing accuracies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='middle right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
